{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing objects for n-dim tead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "from botorch.models.gp_regression import ExactGP\n",
    "from scipy.stats.qmc import LatinHypercube\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "# test using true function rather than model\n",
    "dtype = torch.double\n",
    "def f_test(x):\n",
    "    return torch.sin(x).sum(dim=1, keepdim=True)\n",
    "h = 1e-4\n",
    "x = torch.rand(20, 2, dtype=dtype)\n",
    "num_data = x.shape[0]\n",
    "num_dim = x.shape[1]\n",
    "delta_s = torch.zeros(num_data, num_dim)\n",
    "for i in range(0, num_data):\n",
    "    for j in range(0, num_dim):\n",
    "        dx = torch.zeros(1, num_dim)\n",
    "        dx[:,j] = h  # set the dimension for the gradient to have a step\n",
    "        x_lo = x[i] - dx  # element-wise subtract\n",
    "        x_hi = x[i] + dx  # element-wise addition\n",
    "        y_lo = f_test(x_lo)  # unsqueeze to match model syntax\n",
    "        y_hi = f_test(x_hi)  # unsqueeze to match model syntax\n",
    "        delta_s[i, j] = (y_hi - y_lo)/(2*h)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.9844, 0.6934],\n        [0.9841, 0.8323],\n        [0.6485, 0.7158],\n        [0.9577, 0.9746],\n        [0.9907, 0.7200],\n        [0.9451, 0.9059],\n        [0.9012, 0.6410],\n        [0.9759, 0.9635],\n        [0.9896, 0.9750],\n        [0.9964, 0.9930],\n        [0.8037, 0.9663],\n        [0.9608, 0.7145],\n        [0.7672, 0.9873],\n        [0.8886, 0.8604],\n        [0.9977, 0.7208],\n        [0.9830, 0.7669],\n        [0.9907, 0.7383],\n        [0.9976, 0.9974],\n        [0.8876, 0.9699],\n        [0.9748, 0.9314]])"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_s"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.9844, 0.6934], dtype=torch.float64)"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cos(x[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "def nfinite_diff(model):\n",
    "    \"\"\"get approx gradient at model training points\"\"\"\n",
    "    # assumes 1d input... see implementation in [3] for update to n-D\n",
    "    h = 1e-4\n",
    "    x = model.train_inputs[0]\n",
    "    num_data = x.shape[0]\n",
    "    num_dim = x.shape[1]\n",
    "    delta_s = torch.zeros(num_data, num_dim)\n",
    "    for i in range(0, num_data):\n",
    "        for j in range(0, num_dim):\n",
    "            dx = torch.zeros(1, num_dim)\n",
    "            dx[:,j] = h  # set the dimension for the gradient to have a step\n",
    "            x_lo = x[i] - dx  # element-wise subtract\n",
    "            x_hi = x[i] + dx  # element-wise addition\n",
    "            y_lo = model(x_lo.unsqueeze(0)).mean  # unsqueeze to match model syntax\n",
    "            y_hi = model(x_hi.unsqueeze(0)).mean  # unsqueeze to match model syntax\n",
    "            delta_s[i, j] = (y_hi - y_lo)/(2*h)\n",
    "    return delta_s"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "dtype = torch.double\n",
    "from botorch.models import SingleTaskGP\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch import fit_gpytorch_mll\n",
    "\n",
    "train_X = torch.rand(20, 2, dtype=dtype)\n",
    "train_Y = torch.sin(train_X).sum(dim=1, keepdim=True)\n",
    "model_example = SingleTaskGP(train_X, train_Y)\n",
    "mll_example = ExactMarginalLogLikelihood(model_example.likelihood, model_example)\n",
    "fitting = fit_gpytorch_mll(mll_example)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "temp = nfinite_diff(model_example)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 0.]])"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(1,2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "temp12 = torch.zeros(1, 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 0.]])"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp12"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "temp12[:,1] = 0.5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.0000, 0.5000]])"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp12"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.0000, 0.5000]])"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(1,2) - temp12"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.7887, 0.9993], dtype=torch.float64)"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cos(train_X[3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.9260, 0.4882],\n        [0.8499, 0.8118],\n        [0.4858, 0.0084],\n        [0.6621, 0.0370],\n        [0.2010, 0.5979],\n        [0.6886, 0.3785],\n        [0.5132, 0.5229],\n        [0.1427, 0.5575],\n        [0.3726, 0.9736],\n        [0.5371, 0.0760],\n        [0.5911, 0.0370],\n        [0.0936, 0.5676],\n        [0.7469, 0.9782],\n        [0.2958, 0.2547],\n        [0.8592, 0.5713],\n        [0.0806, 0.6916],\n        [0.2510, 0.5761],\n        [0.8902, 0.8409],\n        [0.6016, 0.9491],\n        [0.0627, 0.6578]], dtype=torch.float64)"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.5726, 0.8757],\n        [0.6051, 0.6663],\n        [0.8296, 0.8780],\n        [0.8194, 0.9350],\n        [0.9806, 0.8212],\n        [0.7869, 0.9470],\n        [0.8829, 0.8921],\n        [0.9549, 0.8237],\n        [0.9368, 0.5439],\n        [0.8535, 0.9431],\n        [0.8394, 0.9284],\n        [0.9303, 0.8046],\n        [0.6971, 0.4840],\n        [0.8754, 0.9253],\n        [0.6269, 0.8473],\n        [0.9499, 0.7596],\n        [0.9765, 0.8418],\n        [0.5485, 0.6262],\n        [0.8285, 0.5412],\n        [0.9318, 0.7694]], grad_fn=<CopySlices>)"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.5062)"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sin(torch.tensor(0.8997)) + torch.sin(torch.tensor(0.8082))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.6219, 0.6908], dtype=torch.float64)"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cos(train_X[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.6218)"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cos(torch.tensor(0.8997))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.sin(train_X+)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
