{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# notebook for third canonical problem for multimodal optimization looking for localized extreme\n",
    "# events with agent-based military simulation\n",
    "# Experiment 2.3 - Stochastic, jump discontinuity multimodal localized extrema test problem with 2d inputs\n",
    "# Part 2 - Balanced strategy approach (PIONEER)\n",
    "#\n",
    "# Author: Alex Braafladt\n",
    "# Initial creation: 3/17/23\n",
    "#\n",
    "# Goal: Benchmark state-of-the-art Bayesian Optimization approaches (and QMC/MCS) on a multimodal\n",
    "#       optimization test function focused on localized extrema in 2d\n",
    "#\n",
    "# Notes:\n",
    "# -Using the BoTorch framework [1] and NEI from [4]\n",
    "# -TEAD technique from [2]\n",
    "# -TuRBO technique from [3]\n",
    "#\n",
    "# References:\n",
    "# [1] M. Balandat et al., “BOTORCH: A framework for efficient Monte-Carlo Bayesian optimization,”\n",
    "#     Adv. Neural Inf. Process. Syst., vol. 2020-Decem, no. MC, 2020.\n",
    "# [2] S. Mo et al., “A Taylor Expansion-Based Adaptive Design Strategy for Global Surrogate\n",
    "#     Modeling With Applications in Groundwater Modeling,” Water Resour. Res., vol. 53, no.\n",
    "#     12, pp. 10802–10823, 2017, doi: 10.1002/2017WR021622.\n",
    "# [3] D. Eriksson, M. Pearce, J. R. Gardner, R. Turner, and M. Poloczek, “Scalable global\n",
    "#     optimization via local Bayesian optimization,” Adv. Neural Inf. Process. Syst., vol.\n",
    "#     32, no. NeurIPS, 2019.\n",
    "# [4] B. Letham, B. Karrer, G. Ottoni, and E. Bakshy, “Constrained Bayesian optimization with noisy\n",
    "#     experiments,” Bayesian Anal., vol. 14, no. 2, pp. 495–519, 2019, doi: 10.1214/18-BA1110."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from botorch import fit_gpytorch_mll\n",
    "from botorch.models.gp_regression import SingleTaskGP\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from botorch.models.transforms import Normalize, Standardize\n",
    "\n",
    "\n",
    "# setup\n",
    "dtype = torch.double\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import warnings\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "warnings.filterwarnings('ignore', category=BadInitialCandidatesWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# setup file i/o\n",
    "import os as os\n",
    "import datetime as dt\n",
    "# get current working directory\n",
    "wrkdir = os.getcwd()\n",
    "print('Current working directory: '+wrkdir)\n",
    "# set up a data save directory for all future runs\n",
    "newoutputdir = wrkdir+'\\output'\n",
    "if not os.path.exists(newoutputdir):\n",
    "    os.makedirs(newoutputdir)\n",
    "# set up a new directory to store files for the current run - updates at each new full run of notebook\n",
    "curDatetime = dt.datetime.now()\n",
    "datasavedir = newoutputdir + r'\\\\' + '2.3_mme_2d_pioneer' + str(curDatetime.strftime('%Y%m%d%H%M%S'))\n",
    "if not os.path.exists(datasavedir):\n",
    "    os.makedirs(datasavedir)\n",
    "print('Data save directory: '+datasavedir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# visualize canonical problem\n",
    "def mme_add_2d_plot(x1, x2):\n",
    "    y = (torch.exp(-(100.*(x1-0.65))**2.)) * (torch.exp(-(50.*(x2-0.65))**2.))\n",
    "    y += 0.7*(torch.exp(-(100.*(x1-0.25))**2.)) * (torch.exp(-(50.*(x2-0.35))**2.))\n",
    "    y += 0.8*(torch.exp(-(100.*(x1-0.8))**2.)) * (torch.exp(-(50.*(x2-0.15))**2.))\n",
    "    y += 0.66*(-1.*x2*x1 + 0.1*torch.sin(30.*x1*x2)) + 0.73\n",
    "    return y\n",
    "\n",
    "x1 = torch.arange(0.0, 1.0, 0.01)\n",
    "x2 = torch.arange(0.0, 1.0, 0.01)\n",
    "X1, X2 = torch.meshgrid([x1, x2])\n",
    "Z = mme_add_2d_plot(X1, X2)\n",
    "from matplotlib import ticker, cm\n",
    "fig, ax = plt.subplots(subplot_kw=dict(projection='3d'), figsize=(8,6))\n",
    "\n",
    "from matplotlib.colors import LightSource\n",
    "ls = LightSource(270, 45)\n",
    "rgb = ls.shade(Z.numpy(), cmap=cm.gist_earth, vert_exag=0.1, blend_mode='soft')\n",
    "surf = ax.plot_surface(X1, X2, Z, cmap='Blues', shade=False, cstride=1, rstride=1, linewidth=0)\n",
    "# surf = ax.plot_surface(X1, X2, Z, facecolors=rgb, shade=False)\n",
    "plt.savefig(datasavedir + '/'+'2d_mean_behavior_surface'+'.png')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# visualizing with noise added\n",
    "sigma_max = 0.12\n",
    "sigma_min = 0.02\n",
    "def noise_1_2d(x1, x2):\n",
    "    # mean\n",
    "    y = mme_add_2d_plot(x1, x2)\n",
    "    # noise\n",
    "    noise = torch.zeros(y.shape)\n",
    "    noise += (torch.randn(y.shape) * sigma_max) * (x1 >= 0.61) * (x1 < 0.71) * (x2 >= 0.61) * (x2 < 0.71)  # peak 1\n",
    "    noise += (torch.randn(y.shape) * sigma_max) * (x1 >= 0.21) * (x1 < 0.31) * (x2 >= 0.31) * (x2 < 0.41)  # peak 2\n",
    "    noise += (torch.randn(y.shape) * sigma_max) * (x1 >= 0.76) * (x1 < 0.84) * (x2 >= 0.11) * (x2 < 0.21)  # peak 3\n",
    "    # noise += (torch.randn(y.shape) * (sigma_max - sigma_min) / (1. + torch.exp(-10.*(x1-0.2))) + sigma_min) * (x1 < 0.5) * (x2 < 0.5)\n",
    "    # noise += (torch.randn(y.shape) * (sigma_max - sigma_min) / (1. + torch.exp(10.*(x1-0.75))) + sigma_min) * (x1 >= 0.5) * (x2 >= 0.5)\n",
    "    noise += torch.randn(y.shape) * (sigma_max - sigma_min) * (0.4 / (torch.abs(1.25*y - 0.5) + 0.4))\n",
    "    # jump\n",
    "    y1 = y + noise\n",
    "    y_jump = 0.2 * y1 * (x1 <= 0.45) * (x2 <= 0.58)\n",
    "    y2 = y1 - y_jump\n",
    "    return y2\n",
    "\n",
    "x1 = torch.arange(0.0, 1.0, 0.01)\n",
    "x2 = torch.arange(0.0, 1.0, 0.01)\n",
    "X1, X2 = torch.meshgrid([x1, x2])\n",
    "Z = noise_1_2d(X1, X2)\n",
    "fig, ax = plt.subplots(subplot_kw=dict(projection='3d'), figsize=(10,8))\n",
    "surf = ax.plot_surface(X1, X2, Z, cmap='Blues', shade=False, cstride=1, rstride=1, linewidth=0)\n",
    "plt.savefig(datasavedir + '/'+'2d_mme_noisyjump_surface'+'.png')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# formatting objective function to match the input format for botorch\n",
    "sigma_max = 0.12\n",
    "sigma_min = 0.02\n",
    "def mme_add_2d(X):\n",
    "    x1, x2 = X[..., 0], X[..., 1]\n",
    "    y = (torch.exp(-(100.*(x1-0.65))**2.)) * (torch.exp(-(50.*(x2-0.65))**2.))\n",
    "    y += 0.7*(torch.exp(-(100.*(x1-0.25))**2.)) * (torch.exp(-(50.*(x2-0.35))**2.))\n",
    "    y += 0.8*(torch.exp(-(100.*(x1-0.8))**2.)) * (torch.exp(-(50.*(x2-0.15))**2.))\n",
    "    y += 0.66*(-1.*x2*x1 + 0.1*torch.sin(30.*x1*x2)) + 0.73\n",
    "    return y\n",
    "\n",
    "def mme_2d(X):\n",
    "    x1, x2 = X[..., 0], X[..., 1]\n",
    "    # mean\n",
    "    y = mme_add_2d(X)\n",
    "    # noise\n",
    "    noise = torch.zeros(y.shape)\n",
    "    noise += (torch.randn(y.shape) * sigma_max) * (x1 >= 0.61) * (x1 < 0.71) * (x2 >= 0.61) * (x2 < 0.71)  # peak 1\n",
    "    noise += (torch.randn(y.shape) * sigma_max) * (x1 >= 0.21) * (x1 < 0.31) * (x2 >= 0.31) * (x2 < 0.41)  # peak 2\n",
    "    noise += (torch.randn(y.shape) * sigma_max) * (x1 >= 0.76) * (x1 < 0.84) * (x2 >= 0.11) * (x2 < 0.21)  # peak 3\n",
    "    # noise += (torch.randn(y.shape) * (sigma_max - sigma_min) / (1. + torch.exp(-10.*(x1-0.2))) + sigma_min) * (x1 < 0.5) * (x2 < 0.5)\n",
    "    # noise += (torch.randn(y.shape) * (sigma_max - sigma_min) / (1. + torch.exp(10.*(x1-0.75))) + sigma_min) * (x1 >= 0.5) * (x2 >= 0.5)\n",
    "    noise += torch.randn(y.shape) * (sigma_max - sigma_min) * (0.4 / (torch.abs(1.25*y - 0.5) + 0.4))\n",
    "    # jump\n",
    "    y1 = y + noise\n",
    "    y_jump = 0.2 * y1 * (x1 <= 0.45) * (x2 <= 0.58)\n",
    "    y2 = y1 - y_jump\n",
    "    return y2\n",
    "\n",
    "def outcome_objective(x):\n",
    "    \"\"\"wrapper for the outcome objective function\"\"\"\n",
    "    return mme_2d(x).type_as(x).unsqueeze(-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
